# gpt-from-scratch
This repository contains a from-scratch PyTorch implementation of a character-level GPT-style language model, built as a learning-oriented reimplementation inspired by Andrej Karpathyâ€™s educational work.

The project focuses on core language-modeling fundamentals rather than production optimizations: tokenization, context windows, next-token prediction, batching, and training dynamics on the Tiny Shakespeare dataset.